{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for 2D Project Physical World and Digital World\n",
    "\n",
    "Cohort: # enter your cohort\n",
    "\n",
    "Team No.: # Enter your team number\n",
    "\n",
    "Members:\n",
    "* Student 1 Name (Student ID)\n",
    "* Student 2 Name (Student ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Problem:\n",
    "The time taken to reach thermal equilibrium depends on the heat\n",
    "capacity of the thermometer and heat transfer rate. For example, the thermometer and the temperature sensor\n",
    "provided take more than 100 s to reach quasi‚Äêthermal equilibrium with a water bath. To reduce this waiting time,\n",
    "a predictive model that takes into account the heat capacity and heat transfer rate can be used. Such predictive\n",
    "models are useful in healthcare, trading, etc. \n",
    "\n",
    "approach:\n",
    "therefore, we want to use the knowledge about the heat capacity and heat transfer we learned in Physical world to get the differential equation between the temperature of the thermosensor and the time with the assumption that Tao is relatively constant with respect to the temperature of the water we measured. To verify the assumption, we measured the data from the real world. and We use linear regression model we learned from the DW class to model the data. and then we calculate the accuracy of the model to see how accurate is our data. and finally we add the error term changing with water.\n",
    "further discussion:\n",
    "we assume the linear model because the heat capacity for the lambda do not change usually. but lambda may change because as the temperature rises, the molecule move faster thus make \n",
    "\n",
    "summary:\n",
    "the Tao is verified to be linear despite of small fluactuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Data from Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "Describe how you collect your data and the reasoning behind such approach.\n",
    "How we collected our data:\n",
    "we used thermobottle and 1L water to keep the temperature of the water constant. and then we use the thermometer to measure the temperature of the water. we chose 46 sets of temperature of the water distributed evenly from 60 to 10 celsius by adding cold water inside the hot water. We make sure the start temperature of the thermosensor to be stablized at room temperature(fluactuated from 30 to 25 celsius). We put the thermosensor inside the water at time = 0. and we minimized the time interval every detection for the thermometer. Finally we crop the time of the data to be 30 seconds as we only get access of these data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe how you prepare your data. Include any codes you have here.\n",
    "The output of the data is in txt format, i first used pandas to change it into the excel format and then crop the data. we also unify the time interval for every detection, the time is around 0.962s.\n",
    "def version2():\n",
    "    path = os.getcwd()\n",
    "    dirs = os.listdir(path)\n",
    "    res = pd.DataFrame(np.arange(0.98,400,0.962),columns=['time'])\n",
    "    for file in dirs:\n",
    "        if file[-1] == 't':\n",
    "            with open(file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                temp_data = [round(float(line.strip().split()[1]),3) for line in lines]\n",
    "                temp_data = pd.DataFrame(temp_data,columns=[file[9:12]])\n",
    "                res = pd.concat([res, temp_data], axis=1, join='outer')\n",
    "    res.to_excel('temp_ver2.xls')\n",
    "we also smooth the data using the numpy function to avoid fluactuation of the temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x, window_len=11, window='blackman'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "\n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal\n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "\n",
    "    input:\n",
    "        x: the input signal\n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "\n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "\n",
    "    see also:\n",
    "\n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    "\n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise (ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise (ValueError, \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "    if window_len < 3:\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise (ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "    s = np.r_[x[window_len - 1:0:-1], x, x[-2:-window_len - 1:-1]]\n",
    "    # print(len(s))\n",
    "    if window == 'flat':  # moving average\n",
    "        w = np.ones(window_len, 'd')\n",
    "    else:\n",
    "        w = eval('np.' + window + '(window_len)')\n",
    "\n",
    "    y = np.convolve(w / w.sum(), s, mode='valid')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot the data for Ts vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization():\n",
    "    bunch_object = pd.read_excel('temp_ver3.xls')\n",
    "    time = bunch_object.ix[:, 'time']\n",
    "    for col in bunch_object.columns[1:]:\n",
    "\n",
    "            temp = bunch_object.ix[:,col]\n",
    "            plt.plot(time,temp,color='lightblue')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we process the data as ( (Tw-Ts)/(Tw-Tsi) ) versus time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_data():\n",
    "    data = pd.read_excel('temp_ver3.xls')\n",
    "    for col in data.columns[1:]:\n",
    "\n",
    "        data.ix[:,col] =  np.log( (np.float(col)/10 - np.array(data.ix[:,col]))/((np.float(col)/10)-np.array(data.ix[0,col])) )\n",
    "    data.to_excel('temp_log_ver3.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## and we visualize the log data we plotted\n",
    "def data_visualization_log():\n",
    "    bunch_object = pd.read_excel('temp_log_ver3.xls')\n",
    "    time = bunch_object.ix[:, 'time']\n",
    "    for col in bunch_object.columns[1:]:\n",
    "        temp = bunch_object.ix[:,col]\n",
    "        plt.plot(time,temp,color='lightblue')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "Describe your data and its features. Include any codes or visualization of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "\n",
    "Describe how you train your model. Include any code and output\n",
    "we used linear regression model from scikit learn, because we can visually get from the linear regression model that Tao is constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x,y):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x,y)\n",
    "    return regr.coef_, regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification and Accuracy\n",
    "\n",
    "Describe how you check the accuracy of your model and its result. State any analysis you have and the steps you have taken to improve its accuracy.\n",
    "def plot_linear_regression():\n",
    "    bunch_object = pd.read_excel('temp_log_ver3.xls')\n",
    "    x = bunch_object.ix[:,'time']\n",
    "    coeff_list, intercept_list, temp_list = [], [], []\n",
    "    for col in bunch_object.columns[1:]:\n",
    "\n",
    "        y = bunch_object.ix[:,col]\n",
    "        col = np.float(col) / 10\n",
    "\n",
    "        coeff, intercept = linear_regression(x.reshape(-1,1),y)\n",
    "        coeff_list.append(coeff)\n",
    "        intercept_list.append(intercept)\n",
    "        temp_list.append(col)\n",
    "    temp_list = np.array(temp_list)\n",
    "    coeff_list = np.array(coeff_list)\n",
    "    plt.scatter(temp_list, coeff_list)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Using Instructor's Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction:\n",
    "\n",
    "* Store your trained model into a pickle object which can be loaded. \n",
    "* Read an excel file with the following format:\n",
    "```\n",
    "time (s)\treading\n",
    "0.00\t    25.812\n",
    "0.90\t    28.562\n",
    "1.79\t    31.875\n",
    "2.68\t    35.062\n",
    "3.55\t    37.937\n",
    "4.43\t    40.687\n",
    "5.30\t    43.25\n",
    "```\n",
    "where the first column indicates the time in seconds and the second column indicates the sensor reading in Celsius. \n",
    "* The number of rows in the instructors' data can be of any number. If your code has a minimum number of rows, your code must be able to handle and exit safely when the data provided is less than the required minimum.\n",
    "* Write a code to prepare the data for prediction.\n",
    "* Write a code to predict the final temperature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a code to load your trained model from a pickle object\n",
    "import pickle\n",
    "filename = '' # enter your pickle file name containing the model\n",
    "with open(filename,'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a code to read an excel file\n",
    "import pandas as pd\n",
    "num_test = 9\n",
    "filename = 'temp_' \n",
    "filekey = [] # instructors will key in this\n",
    "dataframe = {} # this is to store the data for different temperature, the keys are in filekey\n",
    "for idx in range(num_test):\n",
    "    dataframe[filekey[idx]] = pd.read_excel(filename+filekey[idx]+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a code to prepare the data for predicting\n",
    "def preprocess(df):\n",
    "    # use this function to extract the features from the data frame\n",
    "    pass\n",
    "\n",
    "data_test = {}\n",
    "for key in filekey:\n",
    "    data_test[key]=preprocess(dataframe[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a code to predict the final temperature\n",
    "# store the predicted temperature in a variable called \"predicted\"\n",
    "# predicted is a dictionary where the keys are listed in filekey\n",
    "\n",
    "predicted = {}\n",
    "for key in filekey:\n",
    "    predicted[key]=model.predict(data_test[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checking accuracy\n",
    "\n",
    "# first instructor will load the actual temp from a pickle object\n",
    "import pickle\n",
    "error_d = {}\n",
    "accuracy_percent_d = {}\n",
    "\n",
    "for test in range(num_test):\n",
    "    filename = 'data_'+filekey[test]+'.pickle'\n",
    "    with open(filename,'rb') as f:\n",
    "        final_temp, worst_temp = pickle.load(f)\n",
    "\n",
    "    # then calculate the error\n",
    "    error_final = abs(final_temp-predicted[filekey[test]])\n",
    "    accuracy_final_percent = 100-error_final/final_temp*100\n",
    "    error_worst = abs(worst_temp-predicted[filekey[test]])\n",
    "    accuracy_worst_percent = 100-error_worst/worst_temp*100\n",
    "    \n",
    "    error_d[filekey[test]] = (error_final, error_worst)\n",
    "    accuracy_percent_d[filekey[test]] = (accuracy_final_percent, accuracy_worst_percent)\n",
    "\n",
    "    # displaying the error\n",
    "    print('===================================')\n",
    "    print('Testing: {}'.format(filekey[test]))\n",
    "    print('Predicted Temp: {:.2f}'.format(predicted[filekey[test]]))\n",
    "    print('Final Sensor Temp: {:.2f}, Alcohol Temp:{:.2f}'.format(final_temp, worst_temp))\n",
    "    print('Error w.r.t Final Sensor Temp: {:.2f} deg, {:.2f}% accuracy'.format(error_final, accuracy_final_percent))\n",
    "    print('Error w.r.t Alcohol Temp: {:.2f} deg, {:.2f}% accuracy'.format(error_worst, accuracy_worst_percent))\n",
    "    \n",
    "avg_final = sum([ final for final, worst in accuracy_percent_d.values()])/len(error_d.values())\n",
    "avg_worst = sum([ worst for final, worst in accuracy_percent_d.values()])/len(error_d.values())\n",
    "print('==============================')\n",
    "print('Average accuracy for final sensor temp: {:.2f}'.format(avg_final))\n",
    "print('AVerage accuracy for alcohol temp: {:.2f}'.format(avg_worst))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
